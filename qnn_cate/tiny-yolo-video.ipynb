{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object detection demo\n",
    "This notebook shows an example of object detection of a live video.\n",
    "To execute this notebook, you will need:\n",
    "* USB Webcam (tested with Logitech c920 and c270) connected to the ZCU100 board\n",
    "* External monitor connected to the Display Port output\n",
    "\n",
    "The network that is used for inference is a variant of Tiny-Yolo, whose topology is illustrated in the following picture.\n",
    "The pynq colored layers have been quantized with 1 bit for weights and 3 bit for activations, and will be executed in the HW accelerator.\n",
    "The HW accelerator has been integrated in a Machine Learning framework called [Darknet](https://pjreddie.com/darknet/), in which the non-quantized layers are executed.\n",
    "\n",
    "\n",
    "![TinierYolo topology](Tinier-YOLO-topology.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle, random\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import qnn\n",
    "from qnn import TinierYolo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instantiate a Classifier\n",
    "Creating a classifier will automatically download the bitstream onto the device. All other initializations are currently performed in the Darknet framework. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = TinierYolo()\n",
    "net = classifier.init_accelerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Launch object detection from input video\n",
    "\n",
    "The object classification will be performed on the video stream captured by the usb webcam (connected to the board). \n",
    "The result live video will be shown in a pop-up window on the display (connected to the board via display port). \n",
    "\n",
    "The only parameter passed to the classifier is the execution time in seconds.\n",
    "\n",
    "The neural network has been trained on the [PASCAL VOC (Visual Object Classes)](http://host.robots.ox.ac.uk/pascal/VOC/) and is able to identify 20 classes of objects in an image, namely: \n",
    "* Person: person\n",
    "* Animal: bird, cat, cow, dog, horse, sheep\n",
    "* Vehicle: aeroplane, bicycle, boat, bus, car, motorbike, train\n",
    "* Indoor: bottle, chair, dining table, potted plant, sofa, tv/monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.video(exec_time=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset the device\n",
    "If previous execution gave the error *darknet: no process found*, please reset the device with the following instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq import Xlnk\n",
    "\n",
    "xlnk = Xlnk();\n",
    "xlnk.xlnk_reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
